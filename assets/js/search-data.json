{
  
    
        "post0": {
            "title": "Local affine features: useful side product",
            "content": "Keypoints are not just points . Wide baseline stereo matching often as perceived as establishing (key-)point correspondences between images. While this might be true for the some local features like SuperPoint [SuperPoint2017], typically it is more than that. . Specifically, detectors like DoG[Lowe99], Harris[Harris88], Hessian[Hessian78], KeyNet[KeyNet2019], ORB[ORB2011], and many others rate on scale-space provide at least 3 parameters: x, y, and scale. . The most of the local descriptors -- SIFT[Lowe99], HardNet[HardNet2017] and so on -- are not rotation invariant and those which are - mostly require complex matching function[RIFT2005], [sGLOH2], so we have to estimamate a patch orientation in order to match reliably. This can be done by various methods: corners center of mass (ORB[ORB2011], dominant gradient orientation (SIFT)[Lowe99] or by some learned estimator (OriNets[OriNet2016],[AffNet2018]). Another way is to rely on smartphone camera IMU or photographer and assume that images are upright[PerdochRetrieval2009]. . Thus, we can assume that if local descriptors match, this means that local feature scale and orientation also match, at least approximately -- see Figure below. Possible exceptions are cases, when the patch is symmetrical and orientation is ambiguous up to some symmetry group. . . In addition, one could assume that we observe the patch not from the fronto-parallel position and try to estimate local normal, or, more precisely, affine shape of the feature point, modeling it as an ellipse instead of circle. One could also think of affine shape estimation as finding the camera position, from where the patch is seen in some &quot;canonical&quot;, fronto-parallel view. . . This gives us 3 points correspondences from a single local feature match, see an example in Figure below. . . Why is it important and how to use it -- see in current post. How to esimate local affine features robustly -- in the next post. . Benefits of local affine features . Making descriptor job easier . The most straightforward benefit of using local affine features is that they increase the repeatability of the detector and potentially cancel out the most of viewpoint difference local patches. This makes possible matching more challenging image pairs. . . . The practice is a little bit more complicated. Our recent benchmark[IMW2020], which measure the accuracy of the outputed fundamental matrix, shows that the difference in using affine and similarity-covariant features is quite minor. Specifically, the relative difference between SIFT vs SIFT-Affine features is 0.5% and between Hessian-SIFT and Hessian-AffNet SIFT is 5.1%, see Table below. . . Therefore, if the only benefit of local features would be to only improve descriptor extraction stage, it would be arguably not worth it. Luckily, there are more benefits, which are more pronounced. . Making RANSAC job easier . Let&#39;s recall how RANSAC works. . Randomly sample a minimally required number of tentative correspondences to fit the geometrical model of the scene: 4 for homography, 7 for epipolar geometry and estimate the model. | Calculate &quot;support&quot;: other correspondeces, which are consistent with the model. | Repeat steps (1), (2) and output the model which is supported with the most of correspondences. If you were lucky and have sampled all-inlier sample, meaning that all correspondences used to estimate the model were correct, you would have a correct model. | Reality is more complicated than I have just described, but the principle is the same. The most important part is the sampling and it is sensitive to inlier ratio $ nu$ - the percentage of the correct correspondences in the set. Lets denote the minimal number of correspondences required to estimate the model as m. To recover the correct model with the confidence p one needs to sample the number of correspondences, which is described by formula: . begin{equation} N = frac{ log{(1 - p)}}{ log{(1 - nu^{m})}} end{equation}Lets plot the how the number of required samples changes with inlier ratio for confidence equal 99%. Note the log scale on Y axis. Different lines are for different minimal sample size m. . . As you can see from the plot above, reducing the minimal sample size required for the model estimation even by 1 saves and order of magnitude of computation. In reality the benefit is a smaller, as modern RANSACs like GC-RANSAC[gcransac2018] and MAGSAC[magsac2019] could estimate the correct model from the sample containing outliers, but it is still huge, especially for low inlier rate cases. . Image retrieval . The ideal case would be to estimate model from just a single sample and that is exactly what is done in spatial reranking paper &quot;Object retrieval with large vocabularies and fast spatial matching&quot; by Philbin et.al [Philbin07]. . Specifically, they are solving an particular object retrieval problem: given an image containing some object, return all the images from the database, which also containg the same object. . The inital list of images is formed by the descriptor distance and then is reranked. Authors propose to approximate a perspective change between two images as an affine image transformation, and count number of feature points, which are reprojected inside the second image. This number produces better ranking that the original short-list. . . Back to wide baseline stereo . While working for spatial re-ranking, 3-degrees of freedom camera model is too rough for the wide baseline stereo. Yet, going from 4 point correspondences (PC) to 2 affine correspondences (AC) for homogaphy and from 7 PC to 3 AC for the fundamental matrix would be huge benefit anyway for the robust model estimation. . Various variant of RANSAC working for local features were proposed in the last 15 years: Perdoch et.al[perd2006epipolar], Pritts et.al.[PrittsRANSAC2013], Barath and Kukelova [Barath2019ICCV], Rodr√≠guez et.al[RANSACAffine2020]. . Finally, the systematic study of using is presented by Barath et.al[barath2020making] in &quot;Making Affine Correspondences Work in Camera Geometry Computation&quot; paper. Authors show that if used naively, affine correspondence lead to worse results, because they are more noisy than point correspondences. However, there is a bag of tricks presented in the paper, which allow to solve the noise issue and make the affine RANSAC working in practice, resulting in orders of magnitude faster computation. . . Application-specific benefits . Besides the wide baseline stereo, local affine features and correspondences have other applications. I will briefly describe some of them here (to be updated). . Image rectification . Instead of matching local features between two images one might match them within a single image. Why would someone do it? This allows finding repeated pattern: think about windows, doors and so on. Typically they have the same physical size, therefore the diffrence in local features around them could tell us about the geometry of the scene and lens distortion. . . This is the idea of the series of works by Pritts and Chum. . . Surface normals estimation . Ivan Eichhardt and Levente Hajder have a series of works, exploiting the local affine correspondences for surface normals estimation[SurfaceNormals2019] . . Summary . Despite not being popular right now, treating keypoints as local affine features has a lot of advantages over the traditional treatment the local correspondence as the point correspondences. In the next post I will describe a way of estimating the local feature affine shape and orientation. . References . [SuperPoint2017] Detone D., Malisiewicz T. and Rabinovich A., ``Superpoint: Self-Supervised Interest Point Detection and Description&#39;&#39;, CVPRW Deep Learning for Visual SLAM, vol. , number , pp. , 2018. . [Lowe99] D. Lowe, ``Object Recognition from Local Scale-Invariant Features&#39;&#39;, ICCV, 1999. . [Harris88] C. Harris and M. Stephens, ``A Combined Corner and Edge Detector&#39;&#39;, Fourth Alvey Vision Conference, 1988. . [Hessian78] P.R. Beaudet, ``Rotationally invariant image operators&#39;&#39;, Proceedings of the 4th International Joint Conference on Pattern Recognition, 1978. . [KeyNet2019] A. Barroso-Laguna, E. Riba, D. Ponsa et al., ``Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters&#39;&#39;, ICCV, 2019. . [ORB2011] E. Rublee, V. Rabaud, K. Konolidge et al., ``ORB: An Efficient Alternative to SIFT or SURF&#39;&#39;, ICCV, 2011. . [HardNet2017] A. Mishchuk, D. Mishkin, F. Radenovic et al., ``Working Hard to Know Your Neighbor&#39;s Margins: Local Descriptor Learning Loss&#39;&#39;, NeurIPS, 2017. . [RIFT2005] {Lazebnik} S., {Schmid} C. and {Ponce} J., ``A sparse texture representation using local affine regions&#39;&#39;, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, number 8, pp. 1265-1278, 2005. . [sGLOH2] {Bellavia} F. and {Colombo} C., ``Rethinking the sGLOH Descriptor&#39;&#39;, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 40, number 4, pp. 931-944, 2018. . [OriNet2016] K. M., Y. Verdie, P. Fua et al., ``Learning to Assign Orientations to Feature Points&#39;&#39;, CVPR, 2016. . [AffNet2018] D. Mishkin, F. Radenovic and J. Matas, ``Repeatability is Not Enough: Learning Affine Regions via Discriminability&#39;&#39;, ECCV, 2018. . [PerdochRetrieval2009] M. {Perd&#39;och}, O. {Chum} and J. {Matas}, ``Efficient representation of local geometry for large scale object retrieval&#39;&#39;, CVPR, 2009. . [IMW2020] Jin Yuhe, Mishkin Dmytro, Mishchuk Anastasiia et al., ``Image Matching across Wide Baselines: From Paper to Practice&#39;&#39;, arXiv preprint arXiv:2003.01587, vol. , number , pp. , 2020. . [gcransac2018] D. Barath and J. Matas, ``Graph-Cut RANSAC&#39;&#39;, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. . [magsac2019] J.N. Daniel Barath, ``MAGSAC: marginalizing sample consensus&#39;&#39;, CVPR, 2019. . [Philbin07] J. Philbin, O. Chum, M. Isard et al., ``Object Retrieval with Large Vocabularies and Fast Spatial Matching&#39;&#39;, CVPR, 2007. . [perd2006epipolar] M. Perd&#39;och, J. Matas and O. Chum, ``Epipolar geometry from two correspondences&#39;&#39;, ICPR, 2006. . [PrittsRANSAC2013] J. {Pritts}, O. {Chum} and J. {Matas}, ``Approximate models for fast and accurate epipolar geometry estimation&#39;&#39;, 2013 28th International Conference on Image and Vision Computing New Zealand (IVCNZ 2013), 2013. . [Barath2019ICCV] D. Barath and Z. Kukelova, ``Homography From Two Orientation- and Scale-Covariant Features&#39;&#39;, ICCV, 2019. . [RANSACAffine2020] M. {Rodr√≠guez}, G. {Facciolo}, R. G. et al., ``Robust estimation of local affine maps and its applications to image matching&#39;&#39;, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV), 2020. . [barath2020making] Barath Daniel, Polic Michal, F√∂rstner Wolfgang et al., ``Making Affine Correspondences Work in Camera Geometry Computation&#39;&#39;, arXiv preprint arXiv:2007.10032, vol. , number , pp. , 2020. . [SurfaceNormals2019] {Bar√°th} D., {Eichhardt} I. and {Hajder} L., ``Optimal Multi-View Surface Normal Estimation Using Affine Correspondences&#39;&#39;, IEEE Transactions on Image Processing, vol. 28, number 7, pp. 3301-3311, 2019. .",
            "url": "/wide-baseline-stereo-blog/2020/07/17/affine-correspondences.html",
            "relUrl": "/2020/07/17/affine-correspondences.html",
            "date": " ‚Ä¢ Jul 17, 2020"
        }
        
    
  
    
  
    
        ,"post2": {
            "title": "The Role of Wide Baseline Stereo in the Deep Learning World",
            "content": "Rise of Wide Baseline Stereo . The wide baseline stereo (WBS) is a process of establishing correspondences between pixels and/or regions between images depicting the same object or scene and estimation geometric relationship between the cameras, which produced that images. . . One of the first succesful solutions for the WBS problem was proposed by Schmid and Mohr [Schmid1995] in 1995. It was later extended by Beardsley, Torr and Zisserman[Beardsley96] by adding RANSAC robust geometry estimation and later refined by Pritchett and Zisserman [Pritchett1998,Pritchett1998b] in 1998. The general pipeline remains mostly the same until now [WBSTorr99,CsurkaReview2018]. The currently adopted version of the wide baseline stereo algorithm is shown below. . . The algorithm can be summarized as the following: . Compute interest points/regions in all images independently | For each interest point/region compute a descriptor of their neigborhood (local patch). | Establish tentative corresponces between interest points based on their descriptors. | Robustly estimate geometric relation between two images based on tentative correspondences with RANSAC. | The reason of steps 1 and 2 done on the both images separately is that in general wide baseline stereo is not limited to pairs of images, but rather to a collections of them. If all the steps are done pairwise, then the computational complexity is $O(n^2)$. The more steps done seperately - the more efficient algorithm is. . Quick expansion . This algorithm significantly changed computer vision landscape for next forteen years. . Soon after introducing the algorithm, there it become clear that its quality significantly depends on quality of each component, i.e. local feature detector, descriptor, and geometry estimation. Pleora of new detectors and descriptors were proposed, with the most cited computer vision paper ever SIFT local feature[Lowe99]. . It is worth noting, that SIFT became popular only after Mikolajczyk benchmark paper [MikoDescEval2003,Mikolajczyk05], showed it superiority to the rest of alternatives. . Robust geometry estimation was also a hot topic: a lot of improvements over vanilla RANSAC were proposed: LO-RANSAC[LOransac2003], DEGENSAC[Degensac2005], MLESAC[MLESAC00] . Success of wide baseline stereo with SIFT features led to aplication of its components to other computer vision tasks, which were reformulated through wide baseline stereo lens: . Scalable image search. Sivic and Zisserman in famous &quot;Video Google&quot; paper[VideoGoogle2003] proposed to treat local features as &quot;visual words&quot; and use ideas from text processing for searching in image collections. Later even more WBS elements were re-introduced to image search, most notable -- spatial verification[Philbin07]: simplified RANSAC procedure to verify if visual word matches were spatially consistent. | . . Image classification was performed by placing some classifier (SVM, random forest, etc) on top of some encoding of the SIFT-like descriptors, extracted sparsely[Fergus03,CsurkaBoK2004] or densely[Lazebnik06]. | . . Object detection was formulated as relaxed wide baseline stereo problem[Chum2007Exemplar] or as classification of SIFT-like features inside a sliding window [HoG2005] | . . Semantic segmentation was performed by classicication of local region descriptors, typically, SIFT and color features and postprocessing afterwards[Superparsing2010]. | . Of course,wide baseline stereo was also used for its direct applications: . 3D reconstruction was based on camera poses and 3D points, estimated with help of SIFT features [PhotoTourism2006,RomeInDay2009,COLMAP2016] | . . SLAM(Simultaneous localization and mapping) [Se02,PTAM2007,Mur15] were based on fast version of local feature detectors and descriptors. . | Panorama stiching [Brown07] and, more generally, feature-based image registration[DualBootstrap2003] were initalized with a geometry obtained by WBS and then further optimized . | . Deep Learning Invasion: retreal to the geometrical fortress . In 2012 deep learning-based AlexNet[AlexNet2012] approach beat all the methods in image classification. Soon after, Razavian et.al[Astounding2014] have shown that convolutional neural networks (CNNs) pre-trained on the Imagenet outperform more complex traditional solutions in image and scene classification, object detection and image search. Deep learning solutions, be it pretrained or end-to-end learned networks quickly become the default solution for the most of computer vision problems. . . However, there was still an area, where deep learned solutions failed, sometimes spectacularly: geometry-related tasks. Wide baseline stereo[Melekhov2017relativePoseCnn], visual localization[PoseNet2015]}, SLAM are still areas, where the classical wide baseline stereo dominates[sattler2019understanding,zhou2019learn]. . The full reasons why convolution pipelines are failing for geometrical tasks are yet to understand, but the current hypothesis are the following: . CNN-based pose predictions predictions are roughly equivalent to retrieval of most similar image from the training set and outputing its pose.[sattler2019understanding] This phenomenum is also observed in related area: single-view 3D reconstruction[Tatarchenko2019]. | Geometric and arithmetic operations are hard to represent via vanilla neural networks (i.e. matrix multiplication with non-linearity) and they may require specialized building blocks, resembling operations of algorithmic or geometric methods, e.g. spatial transformers[STN2015] and arithmetic units[NALU2018,NAU2020]. Even with special structure such networks require &quot;careful initialization, restricting parameter space, and regularizing for sparsity&quot;[NAU2020]. | Vanilla CNNs are not covariant to even simple geometric transformation like translation [MakeCNNShiftInvariant2019], scaling and especially rotation [GroupEqCNN2016]. Unlike them, WBS baseline is grounded on scale-space theory [lindeberg2013scale] and local patches are geometrically normalilzed before description. | Predictions of the CNNs can be altered by change in a small localized area [AdvPatch2017] or even single pixel [OnePixelAttack2019], while the wide baseline stereo methods require the consensus of different independent regions. | . Today: assimilation and merging . Wide baseline stereo as a task: formulate differentiably and learn modules . Wide baseline stereo as a task is solved today typically by using learned components as a replacement of specific blocks in WBS algorithm[jin2020image] ,e.g. local descriptor like HardNet[HardNet2017], detectors like KeyNet[KeyNet2019], joint detector-descriptor[SuperPoint2017] matching and filtering like SuperGlue[sarlin2019superglue], etc. There are also attempts to formulate the whole downstream task pipeline like SLAM[gradslam2020] in a differentiable way, combining advantages of structured and learning-based approaches. . . . Wide baseline stereo as a idea: consensus of local independent predictions . On the other hand, as an algorithm, wide baseline stereo is summarized into two main ideas . Image should be represented as set of local parts, robust to occlusion, and not influencing each other. | Decision should be based on spatial consensus of local feature correspondences. | One of modern revisit of wide baseline stereo ideas is Capsule Networks[CapsNet2011,CapsNet2017]. Unlike CNNs, they encode not only intensity of feature responce, but also its location and require a geometric agreement between object parts for outputing a confident prediction. . Similar ideas are now explored for ensuring adversarial robustness of CNNs[li2020extreme]. . While wide baseline stereo is far from the mainstream now, it continues to play an important role in computer vision. . . References . [Schmid1995] Schmid Cordelia and Mohr Roger, ``Matching by local invariants&#39;&#39;, , vol. , number , pp. , 1995. online . [Beardsley96] P. Beardsley, P. Torr and A. Zisserman, ``3D model acquisition from extended image sequences&#39;&#39;, ECCV, 1996. . [Pritchett1998] P. Pritchett and A. Zisserman, ``Wide baseline stereo matching&#39;&#39;, ICCV, 1998. . [Pritchett1998b] P. Pritchett and A. Zisserman, ``&quot;Matching and Reconstruction from Widely Separated Views&quot;&#39;&#39;, 3D Structure from Multiple Images of Large-Scale Environments, 1998. . [WBSTorr99] P. Torr and A. Zisserman, ``Feature Based Methods for Structure and Motion Estimation&#39;&#39;, Workshop on Vision Algorithms, 1999. . [CsurkaReview2018] {Csurka} Gabriela, {Dance} Christopher R. and {Humenberger} Martin, ``From handcrafted to deep local features&#39;&#39;, arXiv e-prints, vol. , number , pp. , 2018. . [Lowe99] D. Lowe, ``Object Recognition from Local Scale-Invariant Features&#39;&#39;, ICCV, 1999. . [MikoDescEval2003] K. Mikolajczyk and C. Schmid, ``A Performance Evaluation of Local Descriptors&#39;&#39;, CVPR, June 2003. . [Mikolajczyk05] Mikolajczyk K., Tuytelaars T., Schmid C. et al., ``A Comparison of Affine Region Detectors&#39;&#39;, IJCV, vol. 65, number 1/2, pp. 43--72, 2005. . [LOransac2003] O. Chum, J. Matas and J. Kittler, ``Locally Optimized RANSAC&#39;&#39;, Pattern Recognition, 2003. . [Degensac2005] O. Chum, T. Werner and J. Matas, ``Two-View Geometry Estimation Unaffected by a Dominant Plane&#39;&#39;, CVPR, 2005. . [MLESAC00] Torr P.H.S. and Zisserman A., ``MLESAC: A New Robust Estimator with Application to Estimating Image Geometry&#39;&#39;, CVIU, vol. 78, number , pp. 138--156, 2000. . [VideoGoogle2003] J. Sivic and A. Zisserman, ``Video Google: A Text Retrieval Approach to Object Matching in Videos&#39;&#39;, ICCV, 2003. . [Philbin07] J. Philbin, O. Chum, M. Isard et al., ``Object Retrieval with Large Vocabularies and Fast Spatial Matching&#39;&#39;, CVPR, 2007. . [Fergus03] R. Fergus, P. Perona and A. Zisserman, ``Object Class Recognition by Unsupervised Scale-Invariant Learning&#39;&#39;, CVPR, 2003. . [CsurkaBoK2004] C.D. G. Csurka, J. Willamowski, L. Fan et al., ``Visual Categorization with Bags of Keypoints&#39;&#39;, ECCV, 2004. . [Lazebnik06] S. Lazebnik, C. Schmid and J. Ponce, ``Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories&#39;&#39;, CVPR, 2006. . [Chum2007Exemplar] O. {Chum} and A. {Zisserman}, ``An Exemplar Model for Learning Object Classes&#39;&#39;, CVPR, 2007. . [HoG2005] N. {Dalal} and B. {Triggs}, ``Histograms of oriented gradients for human detection&#39;&#39;, CVPR, 2005. . [Superparsing2010] J. Tighe and S. Lazebnik, ``SuperParsing: Scalable Nonparametric Image Parsing with Superpixels&#39;&#39;, ECCV, 2010. . [PhotoTourism2006] Snavely Noah, Seitz Steven M. and Szeliski Richard, ``Photo Tourism: Exploring Photo Collections in 3D&#39;&#39;, ToG, vol. 25, number 3, pp. 835‚Äì846, 2006. . [RomeInDay2009] Agarwal Sameer, Furukawa Yasutaka, Snavely Noah et al., ``Building Rome in a day&#39;&#39;, Communications of the ACM, vol. 54, number , pp. 105--112, 2011. . [COLMAP2016] J. Sch &quot;{o}nberger and J. Frahm, ``Structure-From-Motion Revisited&#39;&#39;, CVPR, 2016. . [Se02] Se S., G. D. and Little J., ``Mobile Robot Localization and Mapping with Uncertainty Using Scale-Invariant Visual Landmarks&#39;&#39;, IJRR, vol. 22, number 8, pp. 735--758, 2002. . [PTAM2007] G. {Klein} and D. {Murray}, ``Parallel Tracking and Mapping for Small AR Workspaces&#39;&#39;, IEEE and ACM International Symposium on Mixed and Augmented Reality, 2007. . [Mur15] Mur-Artal R., Montiel J. and Tard{ &#39;o}s J., ``ORB-Slam: A Versatile and Accurate Monocular Slam System&#39;&#39;, IEEE Transactions on Robotics, vol. 31, number 5, pp. 1147--1163, 2015. . [Brown07] Brown M. and Lowe D., ``Automatic Panoramic Image Stitching Using Invariant Features&#39;&#39;, IJCV, vol. 74, number , pp. 59--73, 2007. . [DualBootstrap2003] V. C., Tsai} {Chia-Ling and {Roysam} B., ``The dual-bootstrap iterative closest point algorithm with application to retinal image registration&#39;&#39;, IEEE Transactions on Medical Imaging, vol. 22, number 11, pp. 1379-1394, 2003. . [AlexNet2012] Alex Krizhevsky, Ilya Sutskever and Geoffrey E., ``ImageNet Classification with Deep Convolutional Neural Networks&#39;&#39;, 2012. . [Astounding2014] A. S., H. {Azizpour}, J. {Sullivan} et al., ``CNN Features Off-the-Shelf: An Astounding Baseline for Recognition&#39;&#39;, CVPRW, 2014. . [Melekhov2017relativePoseCnn] I. Melekhov, J. Ylioinas, J. Kannala et al., ``Relative Camera Pose Estimation Using Convolutional Neural Networks&#39;&#39;, , 2017. online . [PoseNet2015] A. Kendall, M. Grimes and R. Cipolla, ``PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization&#39;&#39;, ICCV, 2015. . [sattler2019understanding] T. Sattler, Q. Zhou, M. Pollefeys et al., ``Understanding the limitations of cnn-based absolute camera pose regression&#39;&#39;, CVPR, 2019. . [zhou2019learn] Q. Zhou, T. Sattler, M. Pollefeys et al., ``To Learn or Not to Learn: Visual Localization from Essential Matrices&#39;&#39;, ICRA, 2020. . [Tatarchenko2019] M. Tatarchenko, S.R. Richter, R. Ranftl et al., ``What Do Single-View 3D Reconstruction Networks Learn?&#39;&#39;, CVPR, 2019. . [STN2015] M. Jaderberg, K. Simonyan and A. Zisserman, ``Spatial transformer networks&#39;&#39;, NeurIPS, 2015. . [NALU2018] A. Trask, F. Hill, S.E. Reed et al., ``Neural arithmetic logic units&#39;&#39;, NeurIPS, 2018. . [NAU2020] A. Madsen and A. Rosenberg, ``Neural Arithmetic Units&#39;&#39;, ICLR, 2020. . [MakeCNNShiftInvariant2019] R. Zhang, ``Making convolutional networks shift-invariant again&#39;&#39;, ICML, 2019. . [GroupEqCNN2016] T. Cohen and M. Welling, ``Group equivariant convolutional networks&#39;&#39;, ICML, 2016. . [lindeberg2013scale] Lindeberg Tony, ``Scale-space theory in computer vision&#39;&#39;, , vol. 256, number , pp. , 2013. . [AdvPatch2017] T. Brown, D. Mane, A. Roy et al., ``Adversarial patch&#39;&#39;, NeurIPSW, 2017. . [OnePixelAttack2019] Su Jiawei, Vargas Danilo Vasconcellos and Sakurai Kouichi, ``One pixel attack for fooling deep neural networks&#39;&#39;, IEEE Transactions on Evolutionary Computation, vol. 23, number 5, pp. 828--841, 2019. . [jin2020image] Jin Yuhe, Mishkin Dmytro, Mishchuk Anastasiia et al., ``Image Matching across Wide Baselines: From Paper to Practice&#39;&#39;, arXiv preprint arXiv:2003.01587, vol. , number , pp. , 2020. . [HardNet2017] A. Mishchuk, D. Mishkin, F. Radenovic et al., ``Working Hard to Know Your Neighbor&#39;s Margins: Local Descriptor Learning Loss&#39;&#39;, NeurIPS, 2017. . [KeyNet2019] A. Barroso-Laguna, E. Riba, D. Ponsa et al., ``Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters&#39;&#39;, ICCV, 2019. . [SuperPoint2017] Detone D., Malisiewicz T. and Rabinovich A., ``Superpoint: Self-Supervised Interest Point Detection and Description&#39;&#39;, CVPRW Deep Learning for Visual SLAM, vol. , number , pp. , 2018. . [sarlin2019superglue] P. Sarlin, D. DeTone, T. Malisiewicz et al., ``SuperGlue: Learning Feature Matching with Graph Neural Networks&#39;&#39;, CVPR, 2020. . [gradslam2020] J. Krishna Murthy, G. Iyer and L. Paull, ``gradSLAM: Dense SLAM meets Automatic Differentiation &#39;&#39;, ICRA, 2020 . . [CapsNet2011] G.E. Hinton, A. Krizhevsky and S.D. Wang, ``Transforming auto-encoders&#39;&#39;, ICANN, 2011. . [CapsNet2017] S. Sabour, N. Frosst and G.E. Hinton, ``Dynamic routing between capsules&#39;&#39;, NeurIPS, 2017. . [li2020extreme] Li Jianguo, Sun Mingjie and Zhang Changshui, ``Extreme Values are Accurate and Robust in Deep Networks&#39;&#39;, , vol. , number , pp. , 2020. online .",
            "url": "/wide-baseline-stereo-blog/2020/03/27/intro.html",
            "relUrl": "/2020/03/27/intro.html",
            "date": " ‚Ä¢ Mar 27, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! My name is Dmytro Mishkin, I am computer vision researcher. This is blog series based on my on-going PhD thesis. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "/wide-baseline-stereo-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}