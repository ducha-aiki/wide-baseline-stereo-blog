<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Patch extraction: devil in details</h1><p class="page-description">How to be smooth and fast</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-22T00:00:00-05:00" itemprop="datePublished">
        Jul 22, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/ducha-aiki/wide-baseline-stereo-blog/tree/master/_notebooks/2020-07-22-patch-extraction.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/wide-baseline-stereo-blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ducha-aiki/wide-baseline-stereo-blog/master?filepath=_notebooks%2F2020-07-22-patch-extraction.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/wide-baseline-stereo-blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ducha-aiki/wide-baseline-stereo-blog/blob/master/_notebooks/2020-07-22-patch-extraction.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/wide-baseline-stereo-blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fducha-aiki%2Fwide-baseline-stereo-blog%2Fblob%2Fmaster%2F_notebooks%2F2020-07-22-patch-extraction.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/wide-baseline-stereo-blog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-22-patch-extraction.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When working with local features one needs to pay attention to even a smallest details, or the whole process can be ruined. One of such details is how to extract the patch, which will be described by local descriptor such as SIFT or HardNet.</p>
<p><img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/att_00000.png" alt="" title="In order to describe the local patch one first has to extract it. Figure from A Few Things One Should Know About Feature Extraction, Description and Matching" /></p>
<p>Unfortunately, we cannot just extract patch from the image by cropping the patch and then resizing it. Or can we? 
Let's check. We will use two versions of image: original and 4x smaller one and would like to extract same-looking fixed size patch from both of them. The patch we want to crop is showed by oriented red circle.</p>
<p><img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/both_imgs.png" alt="" title="Two versions of the same image: original and 4x smaller" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Aliasing">Aliasing<a class="anchor-link" href="#Aliasing"> </a></h2><p>And here what we get by doing a simple crop and resize to 32x32 pixels.</p>
<p><img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/naive_patches.png" alt="" title="Patches, which are extracted from images of different sizes look different, if extraction done in a naive way" /></p>
<p>Doesn't look good. It is called "<a href="https://en.wikipedia.org/wiki/Aliasing">aliasing</a>" - a problem, which arise when we are trying to downscale big images into small resolution. Specifically: the original image contains finer details, than we could represent in thumbnail, which leads to artifacts. 
<img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/ep.jpg" alt="" title="One does not simply extract patch from the image" /></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-solution:-anti-aliasing">The solution: anti-aliasing<a class="anchor-link" href="#The-solution:-anti-aliasing"> </a></h2><p>The solution,  which follows out of <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">sampling theorem</a> is known: remove the details, which cannot be seens in small image first, then resample image to small size.</p>
<p>The simplest way to remove the fine details is to blur image with the Gaussian kernel.</p>
<p>Lets do it and compare the results. 
<img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/all_patches.png" alt="" title="When extracted properly, patches look same" /></p>
<p>By the way, you can try for yourself, all the required code is <a href="https://github.com/kornia/kornia-examples/blob/master/aliased-and-not-aliased-patch-extraction.ipynb">here, in kornia-examples</a></p>
<h2 id="Performance">Performance<a class="anchor-link" href="#Performance"> </a></h2><p>The problem is solved. Or is it?</p>
<p>The problem with properly antialiased patch extraction is that it is quite slow for two reasons. First, blurring a whole image is a costly operation. But, the worst part is that the required amount of blur depends on the patch size in the original image, or, in other words, keypoint scale. So for extracting, say 8000 patches, one needs to perform blurring 8000 times. Moreover, if one wants to extract elongated region and warp it to the square patch, the amount of blur in vertical and horizontal directions should be different!</p>
<p>What can be done? Well, instead of doing blurring 8000 times, one could create so called scale pyramid and then pick the level, which is the closest to optimal one, predicted by theorem.</p>
<p><img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/Image_pyramid.png" alt="" title="Image from Wikimedia by wiki-user Cmglee https://en.wikipedia.org/wiki/File:Image_pyramid.svg" /></p>
<p>This is exactly, what kornia function <a href="https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.extract_patches_from_pyramid">extract_patches_from_pyramid</a> does.</p>
<p>Also - I have a bit cheated with you above: the "anti-aliased" patches were actually extracted using the function above.</p>
<h2 id="How-it-impacts-local-descriptor-matching?">How it impacts local descriptor matching?<a class="anchor-link" href="#How-it-impacts-local-descriptor-matching?"> </a></h2><p>Let's do the toy example first - describe four patches we have in the example above with HardNet descriptor and calculate the distance between them.</p>
<p><img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/att_00001.png" alt="" title="Descriptor difference between antialiased patches is 0.09 and between naively extracted -- 0.44" /></p>
<p>So the descriptor difference between antialiased patches is 0.09 and between naively extracted -- 0.44. 0.09 is not a big deal, but 0.44 is a lot, actually.</p>
<p>Let's move to the non-toy example from the paper devoted to this topic: "<a href="http://cmp.felk.cvut.cz/~mishkdmy/lenc-2014-features-cvww.pdf">A Few Things One Should Know About Feature Extraction, Description and
Matching</a>"[<a class="latex_cit" id="call-PatchExtraction2014" href="#cit-PatchExtraction2014">PatchExtraction2014</a>].</p>
<p>The original data is lost I am too lazy to redo the experiments for the post, so I will just copy-past images with results. Here are abbrevations used in the paper:</p>
<ul>
<li><p><strong>OPE</strong> -- Optimal Patch Extraction. The most correct and slow way of extracting, including different amount of bluring in different directions.</p>
</li>
<li><p><strong>NBPE</strong> -- No-Blur Patch Extraction. The most naive way we started with</p>
</li>
<li><p><strong>PNBPE</strong> -- Pyramid, No-Blur Patch Extraction. The one, we described above - sampling patches from scale pyramid.</p>
</li>
<li><p><strong>PSPE</strong> Pyramid-Smoothing Patch Extraction. Pick the matching pyramid level and then add anisotropic blur missing.</p>
</li>
</ul>
<p>As you can see, doing things optimally is quite slow. 
<img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/att_00003.png" alt="image.png" title="Time spent on a various stages of local feature extraction" /></p>
<p>Now let's see how it influences performance.</p>
<p><img src="/wide-baseline-stereo-blog/images/copied_from_nb/2020-07-22-patch-extraction_files/att_00005.png" alt="" title="Number of matches for MSER and Hessian-Affine + SIFT on Grffity sequence of Oxford-Affine dataset for different patch extraction methods" /></p>
<p>It looks like that influence is smaller than we thought. But recall that the experiment above is for SIFT descriptor only.  Doing pyramid helps for the small viewpoint change almost as good, as going fully optimal, but with increasing the viewpoint difference, such approximation degrades. Moreover, it influnces MSER detector much more that than Hessian-Affine.</p>
<p>How does it work with deep descriptors like HardNet or SoSNet?  That is the question which not answered yet. Drop me a message if you want to do it yourself and we can do the follow-up post together.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">References<a class="anchor-link" href="#References"> </a></h1><p>[<a id="cit-PatchExtraction2014" href="#call-PatchExtraction2014">PatchExtraction2014</a>] K. Lenc, J. Matas and D. Mishkin, ``<em>A few things one should know about feature extraction, description and matching</em>'', Proceedings of the Computer Vision Winter Workshop,  2014.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ducha-aiki/wide-baseline-stereo-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/wide-baseline-stereo-blog/2020/07/22/patch-extraction.html" hidden></a>
</article>
