<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="/wide-baseline-stereo-blog/feed.xml" rel="self" type="application/atom+xml" /><link href="/wide-baseline-stereo-blog/" rel="alternate" type="text/html" /><updated>2020-03-27T17:24:07-05:00</updated><id>/wide-baseline-stereo-blog/feed.xml</id><title type="html">Wide baseline stereo meets deep learning</title><subtitle>Everything you (didn't) want to know about image matching</subtitle><entry><title type="html">The Role of Wide Baseline Stereo in the Deep Learning World</title><link href="/wide-baseline-stereo-blog/2020/03/27/intro.html" rel="alternate" type="text/html" title="The Role of Wide Baseline Stereo in the Deep Learning World" /><published>2020-03-27T00:00:00-05:00</published><updated>2020-03-27T00:00:00-05:00</updated><id>/wide-baseline-stereo-blog/2020/03/27/intro</id><content type="html" xml:base="/wide-baseline-stereo-blog/2020/03/27/intro.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-27-intro.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Rise-of-Wide-Baseline-Stereo&quot;&gt;Rise of Wide Baseline Stereo&lt;a class=&quot;anchor-link&quot; href=&quot;#Rise-of-Wide-Baseline-Stereo&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The wide baseline stereo (WBS) is a process of establishing correspondences between pixels and/or regions between
images depicting the same object or scene and estimation geometric relationship between the cameras, which produced that images.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/match_doll.png&quot; alt=&quot;&quot; title=&quot;Correspondences between two views found by wide baseline stereo algorithm. Photo and doll created by Olha Mishkina&quot; /&gt;&lt;/p&gt;
&lt;!--- ![Wide baseline stereo model. &quot;Baseline&quot; is the distance between cameras. Image by Arne Nordmann (WikiMedia)](00_intro_files/Epipolar_geometry.svg) 
--&gt;

&lt;p&gt;One of the first succesful solutions for the WBS problem was proposed by Pritchett and Zisserman [&lt;a class=&quot;latex_cit&quot; id=&quot;call-Pritchett1998&quot; href=&quot;#cit-Pritchett1998&quot;&gt;Pritchett1998&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-Pritchett1998b&quot; href=&quot;#cit-Pritchett1998b&quot;&gt;Pritchett1998b&lt;/a&gt;] in 1998. The general pipeline remains mostly the same until now [&lt;a class=&quot;latex_cit&quot; id=&quot;call-WBSTorr99&quot; href=&quot;#cit-WBSTorr99&quot;&gt;WBSTorr99&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-CsurkaReview2018&quot; href=&quot;#cit-CsurkaReview2018&quot;&gt;CsurkaReview2018&lt;/a&gt;]. The currently adopted version of the wide baseline stereo algorithm is shown below.&lt;/p&gt;
&lt;!--- 
![image.png](/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00002.png)
--&gt;


&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00000.png&quot; alt=&quot;&quot; title=&quot;Commonly used wide baseline stereo pipeline&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The algorithm can be summarized as the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compute interest points/regions in all images independently&lt;/li&gt;
&lt;li&gt;For each interest point/region compute a descriptor of their neigborhood (local patch).&lt;/li&gt;
&lt;li&gt;Establish tentative corresponces between interest points based on their descriptors.&lt;/li&gt;
&lt;li&gt;Robustly estimate geometric relation between two images based on tentative correspondences with RANSAC.&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Quick-expansion&quot;&gt;Quick expansion&lt;a class=&quot;anchor-link&quot; href=&quot;#Quick-expansion&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This algorithm significantly changed computer vision landscape for next forteen years.&lt;/p&gt;
&lt;p&gt;Soon after introducing the algorithm, there it become clear that its quality significantly depends on quality of each component, i.e. local feature detector, descriptor, and geometry estimation. Pleora of new detectors and descriptors were proposed, with the most cited computer vision paper ever SIFT local feature[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Lowe99&quot; href=&quot;#cit-Lowe99&quot;&gt;Lowe99&lt;/a&gt;].&lt;/p&gt;
&lt;p&gt;It is worth noti ng, that SIFT became popular only after Mikolajczyk benchmark paper [&lt;a class=&quot;latex_cit&quot; id=&quot;call-MikoDescEval2003&quot; href=&quot;#cit-MikoDescEval2003&quot;&gt;MikoDescEval2003&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-Mikolajczyk05&quot; href=&quot;#cit-Mikolajczyk05&quot;&gt;Mikolajczyk05&lt;/a&gt;], showed it superiority to the rest of alternatives.&lt;/p&gt;
&lt;p&gt;Robust geometry estimation was also a hot topic: a lot of improvements over vanilla RANSAC were proposed: LO-RANSAC[&lt;a class=&quot;latex_cit&quot; id=&quot;call-LOransac2003&quot; href=&quot;#cit-LOransac2003&quot;&gt;LOransac2003&lt;/a&gt;], DEGENSAC[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Degensac2005&quot; href=&quot;#cit-Degensac2005&quot;&gt;Degensac2005&lt;/a&gt;], MLESAC[&lt;a class=&quot;latex_cit&quot; id=&quot;call-MLESAC00&quot; href=&quot;#cit-MLESAC00&quot;&gt;MLESAC00&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;Success of wide baseline stereo with SIFT features led to aplication of its components to other computer vision tasks, which were reformulated through wide baseline stereo lens:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Scalable image search&lt;/strong&gt;. Sivic and Zisserman in famous &quot;Video Google&quot; paper[&lt;a class=&quot;latex_cit&quot; id=&quot;call-VideoGoogle2003&quot; href=&quot;#cit-VideoGoogle2003&quot;&gt;VideoGoogle2003&lt;/a&gt;] proposed to treat local features as &quot;visual words&quot; and use ideas from text processing for searching in image collections.  Later even more WBS elements were re-introduced to image search, most notable -- &lt;strong&gt;spatial verification&lt;/strong&gt;[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Philbin07&quot; href=&quot;#cit-Philbin07&quot;&gt;Philbin07&lt;/a&gt;]: simplified RANSAC procedure to verify if visual word matches were spatially consistent.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00004.png&quot; alt=&quot;&quot; title=&quot;Bag of words image search. Image credit: Filip Radenovic http://cmp.felk.cvut.cz/~radenfil/publications/Radenovic-CMPcolloq-2015.11.12.pdf&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Image classification&lt;/strong&gt; was performed by placing some classifier (SVM, random forest, etc) on top of some encoding of the SIFT-like descriptors, extracted sparsely[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Fergus03&quot; href=&quot;#cit-Fergus03&quot;&gt;Fergus03&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-CsurkaBoK2004&quot; href=&quot;#cit-CsurkaBoK2004&quot;&gt;CsurkaBoK2004&lt;/a&gt;] or densely[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Lazebnik06&quot; href=&quot;#cit-Lazebnik06&quot;&gt;Lazebnik06&lt;/a&gt;]. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00005.png&quot; alt=&quot;&quot; title=&quot;Bag of local features representation for classification from Fergus03&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Object detection&lt;/strong&gt; was formulated as relaxed wide baseline stereo problem[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Chum2007Exemplar&quot; href=&quot;#cit-Chum2007Exemplar&quot;&gt;Chum2007Exemplar&lt;/a&gt;] or as classification of SIFT-like features inside a sliding window [&lt;a class=&quot;latex_cit&quot; id=&quot;call-HoG2005&quot; href=&quot;#cit-HoG2005&quot;&gt;HoG2005&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00003.png&quot; alt=&quot;&quot; title=&quot;Exemplar-representation of the classes using local features, cite{Chum2007Exemplar}&quot; /&gt;&lt;/p&gt;
&lt;!--- 
![HoG-based pedestrian detection algorithm](/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00006.png)
![Histogram of gradient visualization](/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00007.png)
--&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Semantic segmentation&lt;/strong&gt; was performed by classicication of local region descriptors, typically, SIFT and color features and postprocessing afterwards[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Superparsing2010&quot; href=&quot;#cit-Superparsing2010&quot;&gt;Superparsing2010&lt;/a&gt;]. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course,wide  baseline stereo was also used for its direct applications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;3D reconstruction&lt;/strong&gt; was based on camera poses and 3D points, estimated with help of SIFT features [&lt;a class=&quot;latex_cit&quot; id=&quot;call-PhotoTourism2006&quot; href=&quot;#cit-PhotoTourism2006&quot;&gt;PhotoTourism2006&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-RomeInDay2009&quot; href=&quot;#cit-RomeInDay2009&quot;&gt;RomeInDay2009&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-COLMAP2016&quot; href=&quot;#cit-COLMAP2016&quot;&gt;COLMAP2016&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00008.png&quot; alt=&quot;&quot; title=&quot;SfM pipeline from COLMAP&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;SLAM(Simultaneous localization and mapping)&lt;/strong&gt; [&lt;a class=&quot;latex_cit&quot; id=&quot;call-Se02&quot; href=&quot;#cit-Se02&quot;&gt;Se02&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-PTAM2007&quot; href=&quot;#cit-PTAM2007&quot;&gt;PTAM2007&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-Mur15&quot; href=&quot;#cit-Mur15&quot;&gt;Mur15&lt;/a&gt;] were based on fast version of local feature detectors and descriptors.&lt;/p&gt;
&lt;!--- 
![ORBSLAM pipeline](/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00009.png)
--&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Panorama stiching&lt;/strong&gt; [&lt;a class=&quot;latex_cit&quot; id=&quot;call-Brown07&quot; href=&quot;#cit-Brown07&quot;&gt;Brown07&lt;/a&gt;] and, more generally, &lt;strong&gt;feature-based image registration&lt;/strong&gt;[&lt;a class=&quot;latex_cit&quot; id=&quot;call-DualBootstrap2003&quot; href=&quot;#cit-DualBootstrap2003&quot;&gt;DualBootstrap2003&lt;/a&gt;] were initalized with a geometry obtained by WBS and then further optimized&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Deep-Learning-Invasion:-retreal-to-the-geometrical-fortress&quot;&gt;Deep Learning Invasion: retreal to the geometrical fortress&lt;a class=&quot;anchor-link&quot; href=&quot;#Deep-Learning-Invasion:-retreal-to-the-geometrical-fortress&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In 2012 deep learning-based AlexNet[&lt;a class=&quot;latex_cit&quot; id=&quot;call-AlexNet2012&quot; href=&quot;#cit-AlexNet2012&quot;&gt;AlexNet2012&lt;/a&gt;] approach beat all the methods in image classification. Soon after, Razavian et.al[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Astounding2014&quot; href=&quot;#cit-Astounding2014&quot;&gt;Astounding2014&lt;/a&gt;] have shown that convolutional neural networks pre-trained on the Imagenet outperform more complex traditional solutions in image and scene classification, object detection and image search.
Deep learning solutions, be it pretrained or end-to-end learned networks quickly become the default solution for the most of computer vision problems.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00010.png&quot; alt=&quot;&quot; title=&quot;CNN representation beats complex traditional pipelines. From Astounding2014&quot; /&gt;&lt;/p&gt;
&lt;p&gt;However, there was still an area, where deep learned solutions failed, sometimes spectacularly: geometry-related tasks.  Wide baseline stereo[&lt;a class=&quot;latex_cit&quot; id=&quot;call-Melekhov2017relativePoseCnn&quot; href=&quot;#cit-Melekhov2017relativePoseCnn&quot;&gt;Melekhov2017relativePoseCnn&lt;/a&gt;], visual localization[&lt;a class=&quot;latex_cit&quot; id=&quot;call-PoseNet2015&quot; href=&quot;#cit-PoseNet2015&quot;&gt;PoseNet2015&lt;/a&gt;]}, SLAM are still areas, where the classical wide baseline stereo dominates[&lt;a class=&quot;latex_cit&quot; id=&quot;call-sattler2019understanding&quot; href=&quot;#cit-sattler2019understanding&quot;&gt;sattler2019understanding&lt;/a&gt;,&lt;a class=&quot;latex_cit&quot; id=&quot;call-zhou2019learn&quot; href=&quot;#cit-zhou2019learn&quot;&gt;zhou2019learn&lt;/a&gt;].&lt;/p&gt;
&lt;h2 id=&quot;Today:-assimilation-and-merging&quot;&gt;Today: assimilation and merging&lt;a class=&quot;anchor-link&quot; href=&quot;#Today:-assimilation-and-merging&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Wide baseline stereo as a task is solved today typically by using learned components as a replacement of specific blocks in WBS algorithm[&lt;a class=&quot;latex_cit&quot; id=&quot;call-jin2020image&quot; href=&quot;#cit-jin2020image&quot;&gt;jin2020image&lt;/a&gt;] ,e.g. local descriptor like HardNet[&lt;a class=&quot;latex_cit&quot; id=&quot;call-HardNet2017&quot; href=&quot;#cit-HardNet2017&quot;&gt;HardNet2017&lt;/a&gt;], detectors like KeyNet[&lt;a class=&quot;latex_cit&quot; id=&quot;call-KeyNet2019&quot; href=&quot;#cit-KeyNet2019&quot;&gt;KeyNet2019&lt;/a&gt;], joint detector-descriptor[&lt;a class=&quot;latex_cit&quot; id=&quot;call-SuperPoint2017&quot; href=&quot;#cit-SuperPoint2017&quot;&gt;SuperPoint2017&lt;/a&gt;] matching and filtering like SuperGlue[&lt;a class=&quot;latex_cit&quot; id=&quot;call-sarlin2019superglue&quot; href=&quot;#cit-sarlin2019superglue&quot;&gt;sarlin2019superglue&lt;/a&gt;], etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/wide-baseline-stereo-blog/images/copied_from_nb/00_intro_files/att_00011.png&quot; alt=&quot;&quot; title=&quot;SuperGlue: separate matching module for handcrafter and learned features&quot; /&gt;&lt;/p&gt;
&lt;p&gt;As an algorithm, wide baseline stereo is summarized into two main ideas&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Image should be represented as set of local parts, robust to occlusion, and not influencing each other.&lt;/li&gt;
&lt;li&gt;Decision should be based on spatial consensus of local feature correspondences.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One of modern revisit of wide baseline stereo ideas is Capsule Networks[&lt;a class=&quot;latex_cit&quot; id=&quot;call-CapsNet2017&quot; href=&quot;#cit-CapsNet2017&quot;&gt;CapsNet2017&lt;/a&gt;]. While wide baseline stereo is far from the mainstream now, it continues to play an important role in computer vision.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;[&lt;a id=&quot;cit-Pritchett1998&quot; href=&quot;#call-Pritchett1998&quot;&gt;Pritchett1998&lt;/a&gt;] P. Pritchett and A. Zisserman, ``&lt;em&gt;Wide baseline stereo matching&lt;/em&gt;'', ICCV,  1998.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Pritchett1998b&quot; href=&quot;#call-Pritchett1998b&quot;&gt;Pritchett1998b&lt;/a&gt;] P. Pritchett and A. Zisserman, ``&lt;em&gt;&quot;Matching and Reconstruction from Widely Separated Views&quot;&lt;/em&gt;'', 3D Structure from Multiple Images of Large-Scale Environments,  1998.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-WBSTorr99&quot; href=&quot;#call-WBSTorr99&quot;&gt;WBSTorr99&lt;/a&gt;] P. Torr and A. Zisserman, ``&lt;em&gt;Feature Based Methods for Structure and Motion Estimation&lt;/em&gt;'', Workshop on Vision Algorithms,  1999.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-CsurkaReview2018&quot; href=&quot;#call-CsurkaReview2018&quot;&gt;CsurkaReview2018&lt;/a&gt;] {Csurka} Gabriela, {Dance} Christopher R. and {Humenberger} Martin, ``&lt;em&gt;From handcrafted to deep local features&lt;/em&gt;'', arXiv e-prints, vol. , number , pp. ,  2018.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Lowe99&quot; href=&quot;#call-Lowe99&quot;&gt;Lowe99&lt;/a&gt;] D. Lowe, ``&lt;em&gt;Object Recognition from Local Scale-Invariant Features&lt;/em&gt;'', ICCV,  1999.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-MikoDescEval2003&quot; href=&quot;#call-MikoDescEval2003&quot;&gt;MikoDescEval2003&lt;/a&gt;] K. Mikolajczyk and C. Schmid, ``&lt;em&gt;A Performance Evaluation of Local Descriptors&lt;/em&gt;'', CVPR, June 2003.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Mikolajczyk05&quot; href=&quot;#call-Mikolajczyk05&quot;&gt;Mikolajczyk05&lt;/a&gt;] Mikolajczyk K., Tuytelaars T., Schmid C. &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;A Comparison of Affine Region Detectors&lt;/em&gt;'', IJCV, vol. 65, number 1/2, pp. 43--72,  2005.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-LOransac2003&quot; href=&quot;#call-LOransac2003&quot;&gt;LOransac2003&lt;/a&gt;] O. Chum, J. Matas and J. Kittler, ``&lt;em&gt;Locally Optimized RANSAC&lt;/em&gt;'', Pattern Recognition,  2003.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Degensac2005&quot; href=&quot;#call-Degensac2005&quot;&gt;Degensac2005&lt;/a&gt;] O. Chum, T. Werner and J. Matas, ``&lt;em&gt;Two-View Geometry Estimation Unaffected by a Dominant Plane&lt;/em&gt;'', CVPR,  2005.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-MLESAC00&quot; href=&quot;#call-MLESAC00&quot;&gt;MLESAC00&lt;/a&gt;] Torr P.H.S. and Zisserman A., ``&lt;em&gt;MLESAC: A New Robust Estimator with Application to Estimating Image Geometry&lt;/em&gt;'', CVIU, vol. 78, number , pp. 138--156,  2000.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-VideoGoogle2003&quot; href=&quot;#call-VideoGoogle2003&quot;&gt;VideoGoogle2003&lt;/a&gt;] J. Sivic and A. Zisserman, ``&lt;em&gt;Video Google: A Text Retrieval Approach to Object Matching in Videos&lt;/em&gt;'', ICCV,  2003.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Philbin07&quot; href=&quot;#call-Philbin07&quot;&gt;Philbin07&lt;/a&gt;] J. Philbin, O. Chum, M. Isard &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Object Retrieval with Large Vocabularies and Fast Spatial Matching&lt;/em&gt;'', CVPR,  2007.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Fergus03&quot; href=&quot;#call-Fergus03&quot;&gt;Fergus03&lt;/a&gt;] R. Fergus, P. Perona and A. Zisserman, ``&lt;em&gt;Object Class Recognition by Unsupervised Scale-Invariant Learning&lt;/em&gt;'', CVPR,  2003.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-CsurkaBoK2004&quot; href=&quot;#call-CsurkaBoK2004&quot;&gt;CsurkaBoK2004&lt;/a&gt;] C.D. G. Csurka, J. Willamowski, L. Fan &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Visual Categorization with Bags of Keypoints&lt;/em&gt;'', ECCV,  2004.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Lazebnik06&quot; href=&quot;#call-Lazebnik06&quot;&gt;Lazebnik06&lt;/a&gt;] S. Lazebnik, C. Schmid and J. Ponce, ``&lt;em&gt;Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories&lt;/em&gt;'', CVPR,  2006.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Chum2007Exemplar&quot; href=&quot;#call-Chum2007Exemplar&quot;&gt;Chum2007Exemplar&lt;/a&gt;] O. {Chum} and A. {Zisserman}, ``&lt;em&gt;An Exemplar Model for Learning Object Classes&lt;/em&gt;'', CVPR,  2007.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-HoG2005&quot; href=&quot;#call-HoG2005&quot;&gt;HoG2005&lt;/a&gt;] N. {Dalal} and B. {Triggs}, ``&lt;em&gt;Histograms of oriented gradients for human detection&lt;/em&gt;'', CVPR,  2005.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Superparsing2010&quot; href=&quot;#call-Superparsing2010&quot;&gt;Superparsing2010&lt;/a&gt;] J. Tighe and S. Lazebnik, ``&lt;em&gt;SuperParsing: Scalable Nonparametric Image Parsing with Superpixels&lt;/em&gt;'', ECCV,  2010.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-PhotoTourism2006&quot; href=&quot;#call-PhotoTourism2006&quot;&gt;PhotoTourism2006&lt;/a&gt;] Snavely Noah, Seitz Steven M. and Szeliski Richard, ``&lt;em&gt;Photo Tourism: Exploring Photo Collections in 3D&lt;/em&gt;'', ToG, vol. 25, number 3, pp. 835–846,  2006.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-RomeInDay2009&quot; href=&quot;#call-RomeInDay2009&quot;&gt;RomeInDay2009&lt;/a&gt;] Agarwal Sameer, Furukawa Yasutaka, Snavely Noah &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Building Rome in a day&lt;/em&gt;'', Communications of the ACM, vol. 54, number , pp. 105--112,  2011.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-COLMAP2016&quot; href=&quot;#call-COLMAP2016&quot;&gt;COLMAP2016&lt;/a&gt;] J. Sch\&quot;{o}nberger and J. Frahm, ``&lt;em&gt;Structure-From-Motion Revisited&lt;/em&gt;'', CVPR,  2016.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Se02&quot; href=&quot;#call-Se02&quot;&gt;Se02&lt;/a&gt;] Se S., G. D. and Little J., ``&lt;em&gt;Mobile Robot Localization and Mapping with Uncertainty Using Scale-Invariant Visual Landmarks&lt;/em&gt;'', IJRR, vol. 22, number 8, pp. 735--758,  2002.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-PTAM2007&quot; href=&quot;#call-PTAM2007&quot;&gt;PTAM2007&lt;/a&gt;] G. {Klein} and D. {Murray}, ``&lt;em&gt;Parallel Tracking and Mapping for Small AR Workspaces&lt;/em&gt;'', IEEE and ACM International Symposium on Mixed and Augmented Reality,  2007.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Mur15&quot; href=&quot;#call-Mur15&quot;&gt;Mur15&lt;/a&gt;] Mur-Artal R., Montiel J. and Tard{\'o}s J., ``&lt;em&gt;ORB-Slam: A Versatile and Accurate Monocular Slam System&lt;/em&gt;'', IEEE Transactions on Robotics, vol. 31, number 5, pp. 1147--1163,  2015.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Brown07&quot; href=&quot;#call-Brown07&quot;&gt;Brown07&lt;/a&gt;] Brown M. and Lowe D., ``&lt;em&gt;Automatic Panoramic Image Stitching Using Invariant Features&lt;/em&gt;'', IJCV, vol. 74, number , pp. 59--73,  2007.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-DualBootstrap2003&quot; href=&quot;#call-DualBootstrap2003&quot;&gt;DualBootstrap2003&lt;/a&gt;] V. C., Tsai} {Chia-Ling and {Roysam} B., ``&lt;em&gt;The dual-bootstrap iterative closest point algorithm with application to retinal image registration&lt;/em&gt;'', IEEE Transactions on Medical Imaging, vol. 22, number 11, pp. 1379-1394,  2003.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-AlexNet2012&quot; href=&quot;#call-AlexNet2012&quot;&gt;AlexNet2012&lt;/a&gt;] Alex Krizhevsky, Ilya Sutskever and Geoffrey E., ``&lt;em&gt;ImageNet Classification with Deep Convolutional Neural Networks&lt;/em&gt;'',  2012.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Astounding2014&quot; href=&quot;#call-Astounding2014&quot;&gt;Astounding2014&lt;/a&gt;] A. S., H. {Azizpour}, J. {Sullivan} &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;CNN Features Off-the-Shelf: An Astounding Baseline for Recognition&lt;/em&gt;'', CVPRW,  2014.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-Melekhov2017relativePoseCnn&quot; href=&quot;#call-Melekhov2017relativePoseCnn&quot;&gt;Melekhov2017relativePoseCnn&lt;/a&gt;] I. Melekhov, J. Ylioinas, J. Kannala &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Relative Camera Pose Estimation Using Convolutional Neural Networks&lt;/em&gt;'', ,  2017.  &lt;a href=&quot;https://arxiv.org/abs/1702.01381&quot;&gt;online&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-PoseNet2015&quot; href=&quot;#call-PoseNet2015&quot;&gt;PoseNet2015&lt;/a&gt;] A. Kendall, M. Grimes and R. Cipolla, ``&lt;em&gt;PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization&lt;/em&gt;'', ICCV,  2015.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-sattler2019understanding&quot; href=&quot;#call-sattler2019understanding&quot;&gt;sattler2019understanding&lt;/a&gt;] T. Sattler, Q. Zhou, M. Pollefeys &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Understanding the limitations of cnn-based absolute camera pose regression&lt;/em&gt;'', CVPR,  2019.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-zhou2019learn&quot; href=&quot;#call-zhou2019learn&quot;&gt;zhou2019learn&lt;/a&gt;] Q. Zhou, T. Sattler, M. Pollefeys &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;To Learn or Not to Learn: Visual Localization from Essential Matrices&lt;/em&gt;'', ICRA,  2020.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-jin2020image&quot; href=&quot;#call-jin2020image&quot;&gt;jin2020image&lt;/a&gt;] Jin Yuhe, Mishkin Dmytro, Mishchuk Anastasiia &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Image Matching across Wide Baselines: From Paper to Practice&lt;/em&gt;'', arXiv preprint arXiv:2003.01587, vol. , number , pp. ,  2020.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-HardNet2017&quot; href=&quot;#call-HardNet2017&quot;&gt;HardNet2017&lt;/a&gt;] A. Mishchuk, D. Mishkin, F. Radenovic &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Working Hard to Know Your Neighbor's Margins: Local Descriptor Learning Loss&lt;/em&gt;'', NeurIPS,  2017.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-KeyNet2019&quot; href=&quot;#call-KeyNet2019&quot;&gt;KeyNet2019&lt;/a&gt;] A. Barroso-Laguna, E. Riba, D. Ponsa &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters&lt;/em&gt;'', ICCV,  2019.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-SuperPoint2017&quot; href=&quot;#call-SuperPoint2017&quot;&gt;SuperPoint2017&lt;/a&gt;] Detone D., Malisiewicz T. and Rabinovich A., ``&lt;em&gt;Superpoint: Self-Supervised Interest Point Detection and Description&lt;/em&gt;'', CVPRW Deep Learning for Visual SLAM, vol. , number , pp. ,  2018.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-sarlin2019superglue&quot; href=&quot;#call-sarlin2019superglue&quot;&gt;sarlin2019superglue&lt;/a&gt;] P. Sarlin, D. DeTone, T. Malisiewicz &lt;em&gt;et al.&lt;/em&gt;, ``&lt;em&gt;SuperGlue: Learning Feature Matching with Graph Neural Networks&lt;/em&gt;'', CVPR,  2020.&lt;/p&gt;
&lt;p&gt;[&lt;a id=&quot;cit-CapsNet2017&quot; href=&quot;#call-CapsNet2017&quot;&gt;CapsNet2017&lt;/a&gt;] S. Sabour, N. Frosst and G.E. Hinton, ``&lt;em&gt;Dynamic routing between capsules&lt;/em&gt;'', NeurIPS,  2017.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>