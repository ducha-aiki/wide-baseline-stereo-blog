{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Patch extraction: devil in details\"\n",
    "> \"How to be smooth and fast\"\n",
    "- toc: false\n",
    "- image: images/ep.jpg\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- hide: false\n",
    "- search_exclude: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with local features one needs to pay attention to even a smallest details, or the whole process can be ruined. One of such details is how to extract the patch, which will be described by local descriptor such as SIFT or HardNet. \n",
    "\n",
    "![](2020-07-22-patch-extraction_files/att_00000.png \"In order to describe the local patch one first has to extract it. Figure from A Few Things One Should Know About Feature Extraction, Description and Matching\")\n",
    "\n",
    "Unfortunately, we cannot just extract patch from the image by cropping the patch and then resizing it. Or can we? \n",
    "Let's check. We will use two versions of image: original and 4x smaller one and would like to extract same-looking fixed size patch from both of them. The patch we want to crop is showed by oriented red circle.\n",
    "\n",
    "![](2020-07-22-patch-extraction_files/both_imgs.png \"Two versions of the same image: original and 4x smaller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aliasing\n",
    "And here what we get by doing a simple crop and resize to 32x32 pixels.\n",
    "\n",
    "![](2020-07-22-patch-extraction_files/naive_patches.png \"Patches, which are extracted from images of different sizes look different, if extraction done in a naive way\")\n",
    "\n",
    "\n",
    "Doesn't look good. It is called \"[aliasing](https://en.wikipedia.org/wiki/Aliasing)\" - a problem, which arise when we are trying to downscale big images into small resolution. Specifically: the original image contains finer details, than we could represent in thumbnail, which leads to artifacts. \n",
    "![](2020-07-22-patch-extraction_files/ep.jpg \"One does not simply extract patch from the image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The solution: anti-aliasing\n",
    "The solution,  which follows out of [sampling theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem) is known: remove the details, which cannot be seens in small image first, then resample image to small size.\n",
    "\n",
    "The simplest way to remove the fine details is to blur image with the Gaussian kernel. \n",
    "\n",
    "Lets do it and compare the results. \n",
    "![](2020-07-22-patch-extraction_files/all_patches.png \"When extracted properly, patches look same\")\n",
    "\n",
    "By the way, you can try for yourself, all the required code is [here, in kornia-examples](https://github.com/kornia/kornia-examples/blob/master/aliased-and-not-aliased-patch-extraction.ipynb)\n",
    "\n",
    "## Performance\n",
    "\n",
    "The problem is solved. Or is it? \n",
    "\n",
    "The problem with properly antialiased patch extraction is that it is quite slow for two reasons. First, blurring a whole image is a costly operation. But, the worst part is that the required amount of blur depends on the patch size in the original image, or, in other words, keypoint scale. So for extracting, say 8000 patches, one needs to perform blurring 8000 times. Moreover, if one wants to extract elongated region and warp it to the square patch, the amount of blur in vertical and horizontal directions should be different!\n",
    "\n",
    "What can be done? Well, instead of doing blurring 8000 times, one could create so called scale pyramid and then pick the level, which is the closest to optimal one, predicted by theorem.\n",
    "\n",
    "\n",
    "![](2020-07-22-patch-extraction_files/Image_pyramid.png \"Image from Wikimedia by wiki-user Cmglee https://en.wikipedia.org/wiki/File:Image_pyramid.svg\")\n",
    "\n",
    "This is exactly, what kornia function [extract_patches_from_pyramid](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.extract_patches_from_pyramid) does.\n",
    "\n",
    "Also - I have a bit cheated with you above: the \"anti-aliased\" patches were actually extracted using the function above. \n",
    "\n",
    "\n",
    "## How it impacts local descriptor matching?\n",
    "\n",
    "Let's do the toy example first - describe four patches we have in the example above with HardNet descriptor and calculate the distance between them.\n",
    "\n",
    "![](2020-07-22-patch-extraction_files/att_00001.png \"Descriptor difference between antialiased patches is 0.09 and between naively extracted -- 0.44\")\n",
    "\n",
    "So the descriptor difference between antialiased patches is 0.09 and between naively extracted -- 0.44. 0.09 is not a big deal, but 0.44 is a lot, actually. \n",
    "\n",
    "Let's move to the non-toy example from the paper devoted to this topic: \"[A Few Things One Should Know About Feature Extraction, Description and\n",
    "Matching](http://cmp.felk.cvut.cz/~mishkdmy/lenc-2014-features-cvww.pdf)\"\\cite{PatchExtraction2014}. \n",
    "\n",
    "The original data is lost I am too lazy to redo the experiments for the post, so I will just copy-past images with results. Here are abbrevations used in the paper:\n",
    "\n",
    "- **OPE** -- Optimal Patch Extraction. The most correct and slow way of extracting, including different amount of bluring in different directions.\n",
    "\n",
    "- **NBPE** -- No-Blur Patch Extraction. The most naive way we started with \n",
    "\n",
    "- **PNBPE** -- Pyramid, No-Blur Patch Extraction. The one, we described above - sampling patches from scale pyramid.\n",
    "\n",
    "- **PSPE** Pyramid-Smoothing Patch Extraction. Pick the matching pyramid level and then add anisotropic blur missing.\n",
    "\n",
    "\n",
    "As you can see, doing things optimally is quite slow. \n",
    "![image.png](2020-07-22-patch-extraction_files/att_00003.png \"Time spent on a various stages of local feature extraction\")\n",
    "\n",
    "Now let's see how it influences performance. \n",
    "\n",
    "![](2020-07-22-patch-extraction_files/att_00005.png \"Number of matches for MSER and Hessian-Affine + SIFT on Grffity sequence of Oxford-Affine dataset for different patch extraction methods\")\n",
    "\n",
    "It looks like that influence is smaller than we thought. But recall that the experiment above is for SIFT descriptor only.  Doing pyramid helps for the small viewpoint change almost as good, as going fully optimal, but with increasing the viewpoint difference, such approximation degrades. Moreover, it influnces MSER detector much more that than Hessian-Affine. \n",
    "\n",
    "How does it work with deep descriptors like HardNet or SoSNet?  That is the question which not answered yet. Drop me a message if you want to do it yourself and we can do the follow-up post together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[<a id=\"cit-PatchExtraction2014\" href=\"#call-PatchExtraction2014\">PatchExtraction2014</a>] K. Lenc, J. Matas and D. Mishkin, ``_A few things one should know about feature extraction, description and matching_'', Proceedings of the Computer Vision Winter Workshop,  2014.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "key",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": true,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
